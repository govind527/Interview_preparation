{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revenue Forecasting ML Pipeline - Optimized\n",
    "## Ridge, Lasso & ElasticNet with Advanced Feature Engineering\n",
    "\n",
    "### Pipeline Order (Strict):\n",
    "1. **Feature Engineering** â†’ Create domain-specific features\n",
    "2. **Leakage Checks** â†’ Detect and remove target leakage\n",
    "3. **Missing Value Handling** â†’ Fill NaN and inf values\n",
    "4. **Encoding & Scaling** â†’ StandardScaler for regularization\n",
    "5. **Correlation & Redundancy Removal** â†’ VIF and threshold filtering\n",
    "6. **Feature Selection** â†’ RFE, SelectFromModel, VarianceThreshold\n",
    "7. **Proper Data Splitting** â†’ TimeSeriesSplit for CV\n",
    "8. **Model Test** â†’ Ridge, Lasso, ElasticNet only\n",
    "\n",
    "### Key Domain Features (From Business Logic):\n",
    "- **weighted_revenue**: Expected value = forecast Ã— probability\n",
    "- **revenue_momentum_1m**: Tracks if forecast is growing\n",
    "- **loading_factor**: Historical month-3 loading within quarter\n",
    "- **gap_ratio**: Pipeline maturity (weighted/unweighted)\n",
    "- **coverage_pipeline**: Pipeline sufficiency to hit target\n",
    "- **maturity_rate**: Conversion efficiency (POC â†’ Committed)\n",
    "- **structural_feature**: Quarter loading structure\n",
    "- **pipeline_stability**: Inverse variance of pipeline (stability score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit, cross_val_score, GridSearchCV, \n",
    "    RandomizedSearchCV, cross_validate\n",
    ")\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, f_regression, mutual_info_regression,\n",
    "    RFE, RFECV, VarianceThreshold, SelectFromModel\n",
    ")\n",
    "\n",
    "# Models - Only Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import (\n",
    "    Ridge, Lasso, ElasticNet, \n",
    "    RidgeCV, LassoCV, ElasticNetCV\n",
    ")\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    mean_absolute_percentage_error, median_absolute_error\n",
    ")\n",
    "\n",
    "# Statistical tests\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# For VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 2: Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('revenue_data.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"=\"*70)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date index\n",
    "df_monthly = df.copy()\n",
    "\n",
    "# Create proper date column\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "             'Jul': 7, 'Aug': 8, 'Sept': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "if 'month' in df_monthly.columns:\n",
    "    df_monthly['month_num_parsed'] = df_monthly['month'].map(month_map)\n",
    "    if df_monthly['month_num_parsed'].isnull().any():\n",
    "        df_monthly['month_num_parsed'] = df_monthly['month_num']\n",
    "else:\n",
    "    df_monthly['month_num_parsed'] = df_monthly['month_num']\n",
    "\n",
    "df_monthly['date'] = pd.to_datetime(\n",
    "    df_monthly['year'].astype(str) + '-' + df_monthly['month_num_parsed'].astype(str) + '-01'\n",
    ")\n",
    "\n",
    "df_monthly = df_monthly.sort_values('date').reset_index(drop=True)\n",
    "print(f\"Date range: {df_monthly['date'].min()} to {df_monthly['date'].max()}\")\n",
    "print(f\"Total rows: {len(df_monthly)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 3: Advanced Feature Engineering\n",
    "\n",
    "Creating domain-specific features based on business logic:\n",
    "\n",
    "### Chain of Thought - Feature Reasoning:\n",
    "\n",
    "1. **weighted_revenue = forecast Ã— probability**\n",
    "   - Acts as expected value, stabilizes influence of high-value low-probability deals\n",
    "   - Preserves signal from smaller high-certainty run rate\n",
    "\n",
    "2. **revenue_momentum_1m = lag_1 - lag_2**\n",
    "   - Checks if forecast is growing as we approach future date\n",
    "   - Positive = increasing, Negative = decreasing\n",
    "\n",
    "3. **loading_factor = avg(month 3 revenue) / avg(quarter revenue)**\n",
    "   - Quantifies how much revenue typically loads into month 3\n",
    "   - E.g., 60% means month 3 captures 60% of quarter\n",
    "\n",
    "4. **gap_ratio = weighted forecast / unweighted forecast**\n",
    "   - Pipeline maturity indicator\n",
    "   - Ratio â†’ 1 means most deals are committed stage\n",
    "\n",
    "5. **coverage_pipeline = unweighted pipeline / forecast target**\n",
    "   - Checks if pipeline is sufficient to hit target\n",
    "\n",
    "6. **maturity_rate = committed(t) / pipeline(t-1)**\n",
    "   - Conversion efficiency from POC to committed\n",
    "\n",
    "7. **structural_feature = month3_rev / (month1 + month2 + month3)**\n",
    "   - Quarter loading structure\n",
    "\n",
    "8. **pipeline_stability = 1 / variance(pipeline, 3 months)**\n",
    "   - Inverse variance = stability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 1: BASE TEMPORAL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Quarter Features\n",
    "df_monthly['quarter'] = ((df_monthly['month_num_parsed'] - 1) // 3) + 1\n",
    "df_monthly['month_in_quarter'] = ((df_monthly['month_num_parsed'] - 1) % 3) + 1\n",
    "df_monthly['is_quarter_end'] = (df_monthly['month_in_quarter'] == 3).astype(int)\n",
    "df_monthly['is_q4'] = (df_monthly['quarter'] == 4).astype(int)\n",
    "df_monthly['is_year_end'] = (df_monthly['month_num_parsed'] >= 10).astype(int)\n",
    "df_monthly['is_fiscal_year_end'] = (df_monthly['month_num_parsed'] == 12).astype(int)\n",
    "print(\"âœ“ Quarter indicators created\")\n",
    "\n",
    "# 2. Cyclical Features (encode month as sin/cos for continuity)\n",
    "df_monthly['month_sin'] = np.sin(2 * np.pi * df_monthly['month_num_parsed'] / 12)\n",
    "df_monthly['month_cos'] = np.cos(2 * np.pi * df_monthly['month_num_parsed'] / 12)\n",
    "df_monthly['quarter_sin'] = np.sin(2 * np.pi * df_monthly['quarter'] / 4)\n",
    "df_monthly['quarter_cos'] = np.cos(2 * np.pi * df_monthly['quarter'] / 4)\n",
    "print(\"âœ“ Cyclical features created\")\n",
    "\n",
    "# 3. Year progress\n",
    "df_monthly['year_progress'] = (df_monthly['month_num_parsed'] - 1) / 11\n",
    "df_monthly['quarter_progress'] = (df_monthly['month_in_quarter'] - 1) / 2\n",
    "print(\"âœ“ Progress features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 2: COMMITTED & PIPELINE BASE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Total Committed (no leakage - both are known before actual)\n",
    "df_monthly['total_committed'] = df_monthly['committed_sign_revenue'] + df_monthly['committed_unsig_revenue']\n",
    "print(\"âœ“ Total committed created\")\n",
    "\n",
    "# Total Pipeline (all forecasted revenue)\n",
    "df_monthly['total_pipeline'] = (\n",
    "    df_monthly['committed_sign_revenue'] + \n",
    "    df_monthly['committed_unsig_revenue'] + \n",
    "    df_monthly['wtd_pipeline_revenue']\n",
    ")\n",
    "print(\"âœ“ Total pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 3: WEIGHTED REVENUE (EXPECTED VALUE)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: weighted_revenue = forecast Ã— probability\")\n",
    "print(\"   - Acts as stabilizing force\")\n",
    "print(\"   - Weights down high-value, low-probability deals\")\n",
    "print(\"   - Preserves signal from smaller high-certainty deals\")\n",
    "\n",
    "# Weighted Revenue = probability-adjusted expected value\n",
    "# avg_prob_pct is the probability, apply it to pipeline\n",
    "df_monthly['weighted_pipeline_revenue'] = (\n",
    "    df_monthly['wtd_pipeline_revenue'] * df_monthly['avg_prob_pct']\n",
    ")\n",
    "\n",
    "# Weighted total forecast (committed at 100%, pipeline at probability)\n",
    "df_monthly['weighted_total_forecast'] = (\n",
    "    df_monthly['committed_sign_revenue'] * 1.0 +  # 100% certain\n",
    "    df_monthly['committed_unsig_revenue'] * 0.90 +  # 90% certain\n",
    "    df_monthly['wtd_pipeline_revenue'] * df_monthly['avg_prob_pct']  # prob weighted\n",
    ")\n",
    "\n",
    "# Alternative weighted snapshot (business logic weights)\n",
    "df_monthly['weighted_snapshot'] = (\n",
    "    df_monthly['committed_sign_revenue'] * 1.0 +\n",
    "    df_monthly['committed_unsig_revenue'] * 0.85 +\n",
    "    df_monthly['wtd_pipeline_revenue'] * 0.45\n",
    ")\n",
    "\n",
    "print(\"âœ“ Weighted revenue features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 4: LAG FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Lag Features - Committed Signed\n",
    "for lag in [1, 2, 3]:\n",
    "    df_monthly[f'committed_sign_lag{lag}'] = df_monthly['committed_sign_revenue'].shift(lag)\n",
    "print(\"âœ“ Committed signed lag features (1,2,3) created\")\n",
    "\n",
    "# Lag Features - Committed Unsigned\n",
    "for lag in [1, 2]:\n",
    "    df_monthly[f'committed_unsig_lag{lag}'] = df_monthly['committed_unsig_revenue'].shift(lag)\n",
    "print(\"âœ“ Committed unsigned lag features (1,2) created\")\n",
    "\n",
    "# Lag Features - Pipeline\n",
    "for lag in [1, 2, 3]:\n",
    "    df_monthly[f'pipeline_lag{lag}'] = df_monthly['wtd_pipeline_revenue'].shift(lag)\n",
    "print(\"âœ“ Pipeline lag features (1,2,3) created\")\n",
    "\n",
    "# Lag Features - Total Committed\n",
    "for lag in [1, 2, 3]:\n",
    "    df_monthly[f'total_committed_lag{lag}'] = df_monthly['total_committed'].shift(lag)\n",
    "print(\"âœ“ Total committed lag features (1,2,3) created\")\n",
    "\n",
    "# Lag Features - Total Pipeline\n",
    "for lag in [1, 2]:\n",
    "    df_monthly[f'total_pipeline_lag{lag}'] = df_monthly['total_pipeline'].shift(lag)\n",
    "print(\"âœ“ Total pipeline lag features (1,2) created\")\n",
    "\n",
    "# Lag Features - Weighted Forecast\n",
    "for lag in [1, 2]:\n",
    "    df_monthly[f'weighted_forecast_lag{lag}'] = df_monthly['weighted_total_forecast'].shift(lag)\n",
    "print(\"âœ“ Weighted forecast lag features (1,2) created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 5: REVENUE MOMENTUM\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: revenue_momentum_1m = lag_1 - lag_2\")\n",
    "print(\"   - Positive = forecast revenue is increasing\")\n",
    "print(\"   - Negative = forecast revenue is decreasing\")\n",
    "\n",
    "# Revenue Momentum (1-month)\n",
    "df_monthly['committed_sign_momentum_1m'] = (\n",
    "    df_monthly['committed_sign_lag1'] - df_monthly['committed_sign_lag2']\n",
    ")\n",
    "df_monthly['total_committed_momentum_1m'] = (\n",
    "    df_monthly['total_committed_lag1'] - df_monthly['total_committed_lag2']\n",
    ")\n",
    "df_monthly['pipeline_momentum_1m'] = (\n",
    "    df_monthly['pipeline_lag1'] - df_monthly['pipeline_lag2']\n",
    ")\n",
    "df_monthly['weighted_forecast_momentum_1m'] = (\n",
    "    df_monthly['weighted_forecast_lag1'] - df_monthly['weighted_forecast_lag2']\n",
    ")\n",
    "print(\"âœ“ 1-month momentum features created\")\n",
    "\n",
    "# Revenue Momentum (2-month)\n",
    "df_monthly['committed_sign_momentum_2m'] = (\n",
    "    df_monthly['committed_sign_lag1'] - df_monthly['committed_sign_lag3']\n",
    ")\n",
    "df_monthly['total_committed_momentum_2m'] = (\n",
    "    df_monthly['total_committed_lag1'] - df_monthly['total_committed_lag3']\n",
    ")\n",
    "print(\"âœ“ 2-month momentum features created\")\n",
    "\n",
    "# Acceleration (second derivative)\n",
    "df_monthly['committed_sign_acceleration'] = (\n",
    "    (df_monthly['committed_sign_lag1'] - df_monthly['committed_sign_lag2']) - \n",
    "    (df_monthly['committed_sign_lag2'] - df_monthly['committed_sign_lag3'])\n",
    ")\n",
    "print(\"âœ“ Acceleration features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 6: ROLLING STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Rolling Mean - Committed Signed\n",
    "for window in [3, 6]:\n",
    "    df_monthly[f'committed_sign_rolling_mean_{window}'] = \\\n",
    "        df_monthly['committed_sign_revenue'].rolling(window=window, min_periods=1).mean()\n",
    "print(\"âœ“ Committed signed rolling means (3,6) created\")\n",
    "\n",
    "# Rolling Std - Committed Signed\n",
    "df_monthly['committed_sign_rolling_std_3'] = \\\n",
    "    df_monthly['committed_sign_revenue'].rolling(window=3, min_periods=1).std()\n",
    "df_monthly['committed_sign_rolling_std_6'] = \\\n",
    "    df_monthly['committed_sign_revenue'].rolling(window=6, min_periods=1).std()\n",
    "print(\"âœ“ Committed signed rolling std (3,6) created\")\n",
    "\n",
    "# Rolling Mean/Std - Pipeline\n",
    "for window in [3, 6]:\n",
    "    df_monthly[f'pipeline_rolling_mean_{window}'] = \\\n",
    "        df_monthly['wtd_pipeline_revenue'].rolling(window=window, min_periods=1).mean()\n",
    "df_monthly['pipeline_rolling_std_3'] = \\\n",
    "    df_monthly['wtd_pipeline_revenue'].rolling(window=3, min_periods=1).std()\n",
    "print(\"âœ“ Pipeline rolling stats created\")\n",
    "\n",
    "# Rolling Mean - Total Committed\n",
    "for window in [3, 6]:\n",
    "    df_monthly[f'total_committed_rolling_mean_{window}'] = \\\n",
    "        df_monthly['total_committed'].rolling(window=window, min_periods=1).mean()\n",
    "print(\"âœ“ Total committed rolling means (3,6) created\")\n",
    "\n",
    "# Rolling Min/Max\n",
    "df_monthly['committed_sign_rolling_min_3'] = \\\n",
    "    df_monthly['committed_sign_revenue'].rolling(window=3, min_periods=1).min()\n",
    "df_monthly['committed_sign_rolling_max_3'] = \\\n",
    "    df_monthly['committed_sign_revenue'].rolling(window=3, min_periods=1).max()\n",
    "print(\"âœ“ Rolling min/max features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 7: GAP RATIO (PIPELINE MATURITY)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: gap_ratio = weighted forecast / unweighted forecast\")\n",
    "print(\"   - Ratio approaching 1 = most deals are committed stage\")\n",
    "print(\"   - Lower ratio = more uncertain pipeline deals\")\n",
    "\n",
    "# Gap Ratio = weighted/unweighted (pipeline maturity indicator)\n",
    "df_monthly['gap_ratio'] = (\n",
    "    df_monthly['weighted_total_forecast'] / \n",
    "    (df_monthly['total_pipeline'] + 1)  # +1 to avoid division by zero\n",
    ")\n",
    "\n",
    "# Simplified gap: committed / total_pipeline\n",
    "df_monthly['commitment_gap'] = (\n",
    "    df_monthly['total_committed'] / \n",
    "    (df_monthly['total_pipeline'] + 1)\n",
    ")\n",
    "\n",
    "print(\"âœ“ Gap ratio features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 8: COVERAGE PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: coverage = unweighted pipeline / forecast target\")\n",
    "print(\"   - Checks if pipeline is enough to hit target\")\n",
    "print(\"   - >1 = sufficient coverage\")\n",
    "\n",
    "# Coverage pipeline ratio\n",
    "# Using rolling mean as \"target\" estimate\n",
    "target_estimate = df_monthly['total_committed_rolling_mean_6']\n",
    "df_monthly['coverage_pipeline'] = (\n",
    "    df_monthly['total_pipeline'] / \n",
    "    (target_estimate + 1)\n",
    ")\n",
    "\n",
    "# Pipeline coverage vs weighted forecast\n",
    "df_monthly['pipeline_coverage_weighted'] = (\n",
    "    df_monthly['total_pipeline'] / \n",
    "    (df_monthly['weighted_total_forecast'] + 1)\n",
    ")\n",
    "\n",
    "print(\"âœ“ Coverage pipeline features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 9: MATURITY RATE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: maturity_rate = committed(t) / pipeline(t-1)\")\n",
    "print(\"   - Conversion efficiency from POC to Committed\")\n",
    "print(\"   - High rate = good pipeline conversion\")\n",
    "\n",
    "# Maturity Rate = committed this month / pipeline last month\n",
    "df_monthly['maturity_rate_signed'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['pipeline_lag1'] + 1)\n",
    ")\n",
    "\n",
    "df_monthly['maturity_rate_total'] = (\n",
    "    df_monthly['total_committed'] / \n",
    "    (df_monthly['total_pipeline_lag1'] + 1)\n",
    ")\n",
    "\n",
    "# Conversion efficiency - committed growth relative to pipeline\n",
    "df_monthly['conversion_efficiency'] = (\n",
    "    (df_monthly['committed_sign_revenue'] - df_monthly['committed_sign_lag1']) / \n",
    "    (df_monthly['pipeline_lag1'] + 1)\n",
    ")\n",
    "\n",
    "print(\"âœ“ Maturity rate features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 10: LOADING FACTOR (QUARTER DISTRIBUTION)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: loading_factor = avg(month 3 revenue) / avg(quarter revenue)\")\n",
    "print(\"   - Quantifies how much revenue loads into month 3 of quarter\")\n",
    "print(\"   - E.g., 60% means 60% of quarter revenue comes from month 3\")\n",
    "\n",
    "# Calculate quarterly averages\n",
    "df_monthly['quarter_key'] = df_monthly['year'].astype(str) + '_Q' + df_monthly['quarter'].astype(str)\n",
    "\n",
    "# Create rolling quarter average\n",
    "df_monthly['quarter_rolling_avg'] = df_monthly.groupby('quarter_key')['committed_sign_revenue'].transform('mean')\n",
    "\n",
    "# Loading factor = current month / quarter average\n",
    "df_monthly['loading_factor'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['quarter_rolling_avg'] + 1)\n",
    ")\n",
    "\n",
    "# Month-in-quarter loading pattern\n",
    "df_monthly['month_loading_weight'] = df_monthly['month_in_quarter'] / 3.0\n",
    "\n",
    "print(\"âœ“ Loading factor features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 11: STRUCTURAL FEATURE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: structural_feature = month3_rev / (month1 + month2 + month3)\")\n",
    "print(\"   - Measures quarter loading structure\")\n",
    "print(\"   - High value = back-loaded quarter\")\n",
    "\n",
    "# Cumulative within quarter\n",
    "df_monthly['quarter_cumsum'] = df_monthly.groupby('quarter_key')['committed_sign_revenue'].cumsum()\n",
    "\n",
    "# Structural feature - proportion of quarter revenue at this point\n",
    "df_monthly['structural_feature'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['quarter_cumsum'] + 1)\n",
    ")\n",
    "\n",
    "# Quarter completion ratio\n",
    "quarter_totals = df_monthly.groupby('quarter_key')['committed_sign_revenue'].transform('sum')\n",
    "df_monthly['quarter_completion_pct'] = df_monthly['quarter_cumsum'] / (quarter_totals + 1)\n",
    "\n",
    "print(\"âœ“ Structural features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 12: PIPELINE STABILITY SCORE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ’¡ Reasoning: stability = 1 / variance(pipeline, 3 months)\")\n",
    "print(\"   - Inverse of variance = stability score\")\n",
    "print(\"   - High stability = consistent pipeline\")\n",
    "\n",
    "# Pipeline Stability Score = 1 / variance (3 months)\n",
    "pipeline_variance_3m = df_monthly['wtd_pipeline_revenue'].rolling(window=3, min_periods=1).var()\n",
    "df_monthly['pipeline_stability_3m'] = 1 / (pipeline_variance_3m + 1e6)  # Add large constant to avoid inf\n",
    "\n",
    "# Committed stability\n",
    "committed_variance_3m = df_monthly['committed_sign_revenue'].rolling(window=3, min_periods=1).var()\n",
    "df_monthly['committed_stability_3m'] = 1 / (committed_variance_3m + 1e6)\n",
    "\n",
    "# Coefficient of Variation (normalized stability)\n",
    "df_monthly['pipeline_cv'] = (\n",
    "    df_monthly['pipeline_rolling_std_3'] / \n",
    "    (df_monthly['pipeline_rolling_mean_3'] + 1)\n",
    ")\n",
    "df_monthly['committed_sign_cv'] = (\n",
    "    df_monthly['committed_sign_rolling_std_3'] / \n",
    "    (df_monthly['committed_sign_rolling_mean_3'] + 1)\n",
    ")\n",
    "\n",
    "print(\"âœ“ Pipeline stability features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 13: RATIO FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ratio Features\n",
    "df_monthly['committed_sign_ratio'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['total_committed'] + 1)\n",
    ")\n",
    "df_monthly['pipeline_to_committed_ratio'] = (\n",
    "    df_monthly['wtd_pipeline_revenue'] / \n",
    "    (df_monthly['total_committed'] + 1)\n",
    ")\n",
    "df_monthly['signed_unsigned_ratio'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['committed_unsig_revenue'] + 1)\n",
    ")\n",
    "\n",
    "# Signed to total ratio\n",
    "df_monthly['signed_to_total_ratio'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['total_pipeline'] + 1)\n",
    ")\n",
    "\n",
    "print(\"âœ“ Ratio features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 14: EMA FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# EMA - Committed Signed\n",
    "for span in [3, 6]:\n",
    "    df_monthly[f'committed_sign_ema_{span}'] = \\\n",
    "        df_monthly['committed_sign_revenue'].ewm(span=span, adjust=False).mean()\n",
    "print(\"âœ“ Committed signed EMA (3,6) created\")\n",
    "\n",
    "# EMA - Total Committed\n",
    "for span in [3, 6]:\n",
    "    df_monthly[f'total_committed_ema_{span}'] = \\\n",
    "        df_monthly['total_committed'].ewm(span=span, adjust=False).mean()\n",
    "print(\"âœ“ Total committed EMA (3,6) created\")\n",
    "\n",
    "# EMA - Pipeline\n",
    "df_monthly['pipeline_ema_3'] = df_monthly['wtd_pipeline_revenue'].ewm(span=3, adjust=False).mean()\n",
    "print(\"âœ“ Pipeline EMA created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 15: TREND & DEVIATION FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Trend Features (deviation from rolling mean)\n",
    "df_monthly['committed_sign_trend_3'] = (\n",
    "    df_monthly['committed_sign_revenue'] - df_monthly['committed_sign_rolling_mean_3']\n",
    ")\n",
    "df_monthly['committed_sign_trend_6'] = (\n",
    "    df_monthly['committed_sign_revenue'] - df_monthly['committed_sign_rolling_mean_6']\n",
    ")\n",
    "df_monthly['total_committed_trend'] = (\n",
    "    df_monthly['total_committed'] - df_monthly['total_committed_rolling_mean_3']\n",
    ")\n",
    "print(\"âœ“ Trend features created\")\n",
    "\n",
    "# Relative strength (current vs rolling)\n",
    "df_monthly['committed_sign_relative_strength'] = (\n",
    "    df_monthly['committed_sign_revenue'] / \n",
    "    (df_monthly['committed_sign_rolling_mean_3'] + 1)\n",
    ")\n",
    "print(\"âœ“ Relative strength features created\")\n",
    "\n",
    "# Z-score features\n",
    "df_monthly['committed_sign_zscore'] = (\n",
    "    (df_monthly['committed_sign_revenue'] - df_monthly['committed_sign_rolling_mean_6']) / \n",
    "    (df_monthly['committed_sign_rolling_std_6'] + 1)\n",
    ")\n",
    "print(\"âœ“ Z-score features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 16: YEAR-TO-DATE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Year-to-Date Cumulative\n",
    "df_monthly['ytd_committed_sign'] = df_monthly.groupby('year')['committed_sign_revenue'].cumsum()\n",
    "df_monthly['ytd_total_committed'] = df_monthly.groupby('year')['total_committed'].cumsum()\n",
    "df_monthly['ytd_pipeline'] = df_monthly.groupby('year')['wtd_pipeline_revenue'].cumsum()\n",
    "print(\"âœ“ Year-to-date cumulative features created\")\n",
    "\n",
    "# YTD average\n",
    "df_monthly['ytd_avg_committed'] = (\n",
    "    df_monthly['ytd_committed_sign'] / df_monthly['month_num_parsed']\n",
    ")\n",
    "print(\"âœ“ Year-to-date average features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 17: VELOCITY FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Commitment velocity\n",
    "df_monthly['commitment_velocity'] = df_monthly['total_committed'] - df_monthly['total_committed_lag1']\n",
    "df_monthly['commitment_velocity_3m'] = df_monthly['commitment_velocity'].rolling(window=3, min_periods=1).mean()\n",
    "print(\"âœ“ Commitment velocity features created\")\n",
    "\n",
    "# Pipeline velocity\n",
    "df_monthly['pipeline_velocity'] = df_monthly['wtd_pipeline_revenue'] - df_monthly['pipeline_lag1']\n",
    "print(\"âœ“ Pipeline velocity features created\")\n",
    "\n",
    "# Pipeline to signed flow\n",
    "df_monthly['pipeline_to_signed_flow'] = (\n",
    "    df_monthly['committed_sign_revenue'] - df_monthly['wtd_pipeline_revenue']\n",
    ")\n",
    "print(\"âœ“ Pipeline to signed flow feature created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 18: PERCENTAGE CHANGE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Percentage Changes\n",
    "df_monthly['committed_sign_pct_change'] = df_monthly['committed_sign_revenue'].pct_change()\n",
    "df_monthly['total_committed_pct_change'] = df_monthly['total_committed'].pct_change()\n",
    "df_monthly['pipeline_pct_change'] = df_monthly['wtd_pipeline_revenue'].pct_change()\n",
    "print(\"âœ“ Percentage change features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING - PHASE 19: INTERACTION FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Month Ã— Quarter interactions\n",
    "df_monthly['month_quarter_interaction'] = (\n",
    "    df_monthly['month_in_quarter'] * df_monthly['is_q4']\n",
    ")\n",
    "\n",
    "# Momentum Ã— Stability interactions\n",
    "df_monthly['momentum_stability_interaction'] = (\n",
    "    df_monthly['committed_sign_momentum_1m'] * df_monthly['committed_stability_3m']\n",
    ")\n",
    "\n",
    "# Gap Ã— Coverage interaction\n",
    "df_monthly['gap_coverage_interaction'] = (\n",
    "    df_monthly['gap_ratio'] * df_monthly['coverage_pipeline']\n",
    ")\n",
    "\n",
    "print(\"âœ“ Interaction features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 4: Target Leakage Detection\n",
    "\n",
    "**CRITICAL:** Check for features that have unrealistically high correlation with target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TARGET LEAKAGE DETECTION - PHASE 1: CORRELATION CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check correlation of features with target\n",
    "numeric_cols = df_monthly.select_dtypes(include=[np.number]).columns.tolist()\n",
    "exclude_cols = ['year', 'month_num', 'month_num_parsed', 'actual_revenue', 'date']\n",
    "feature_cols_temp = [col for col in numeric_cols if col not in exclude_cols]\n",
    "\n",
    "print(\"\\nðŸ“Š Features with |correlation| > 0.95 with target (POTENTIAL LEAKAGE):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "leakage_candidates = []\n",
    "for col in feature_cols_temp:\n",
    "    if df_monthly[col].nunique() > 1:  # Skip constant columns\n",
    "        corr = df_monthly[col].corr(df_monthly['actual_revenue'])\n",
    "        if abs(corr) > 0.95:\n",
    "            leakage_candidates.append((col, corr))\n",
    "            print(f\"  âš ï¸ {col}: {corr:.4f}\")\n",
    "\n",
    "if not leakage_candidates:\n",
    "    print(\"  âœ“ No features with correlation > 0.95 found\")\n",
    "\n",
    "print(f\"\\nTotal potential leakage candidates: {len(leakage_candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGET LEAKAGE DETECTION - PHASE 2: LINEAR COMBINATION CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if sum of components equals target (would be leakage)\n",
    "component_sum = (\n",
    "    df_monthly['committed_sign_revenue'] + \n",
    "    df_monthly['committed_unsig_revenue'] + \n",
    "    df_monthly['wtd_pipeline_revenue']\n",
    ")\n",
    "\n",
    "# Compare with actual revenue\n",
    "diff = abs(df_monthly['actual_revenue'] - component_sum)\n",
    "mean_diff = diff.mean()\n",
    "max_diff = diff.max()\n",
    "\n",
    "print(f\"\\nSum of components vs actual_revenue:\")\n",
    "print(f\"  Mean difference: ${mean_diff:,.2f}\")\n",
    "print(f\"  Max difference: ${max_diff:,.2f}\")\n",
    "\n",
    "if mean_diff < 100:\n",
    "    print(\"\\nâš ï¸ WARNING: Components nearly perfectly sum to target!\")\n",
    "    print(\"   Using components directly could cause leakage.\")\n",
    "else:\n",
    "    print(\"\\nâœ“ Components do NOT perfectly reconstruct target. Safe to proceed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGET LEAKAGE DETECTION - PHASE 3: BUSINESS LOGIC REVIEW\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "ðŸ“‹ BUSINESS LOGIC REVIEW:\n",
    "\n",
    "SAFE FEATURES (known before actual revenue):\n",
    "  âœ“ committed_sign_revenue - Signed deals known before close\n",
    "  âœ“ committed_unsig_revenue - Unsigned deals known before close  \n",
    "  âœ“ wtd_pipeline_revenue - Pipeline known before close\n",
    "  âœ“ All lag features - Historical data, no leakage\n",
    "  âœ“ All rolling statistics - Based on historical data\n",
    "  âœ“ All ratio features - Derived from safe base features\n",
    "\n",
    "RESTRICTED FEATURES (use with caution):\n",
    "  âš ï¸ avg_prob_pct - Analyst probability guess\n",
    "     -> Only used for weighting, not as direct predictor\n",
    "     -> weighted_pipeline_revenue is the derived feature\n",
    "\n",
    "REMOVED FEATURES:\n",
    "  âŒ Any feature perfectly correlated (>0.98) with target\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 5: Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MISSING VALUE HANDLING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check missing values before handling\n",
    "missing_before = df_monthly.isnull().sum()\n",
    "missing_cols = missing_before[missing_before > 0]\n",
    "\n",
    "print(f\"\\nColumns with missing values: {len(missing_cols)}\")\n",
    "if len(missing_cols) > 0:\n",
    "    print(\"\\nMissing value counts:\")\n",
    "    for col, count in missing_cols.items():\n",
    "        print(f\"  {col}: {count}\")\n",
    "\n",
    "# Fill NaN values with 0 for numerical columns\n",
    "# (Appropriate for lag features where early rows have no history)\n",
    "df_monthly = df_monthly.fillna(0)\n",
    "\n",
    "# Replace infinite values\n",
    "df_monthly = df_monthly.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Verify\n",
    "missing_after = df_monthly.isnull().sum().sum()\n",
    "inf_count = np.isinf(df_monthly.select_dtypes(include=[np.number])).sum().sum()\n",
    "\n",
    "print(f\"\\nâœ“ Missing values after handling: {missing_after}\")\n",
    "print(f\"âœ“ Infinite values after handling: {inf_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 6: Proper Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DATA SPLITTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define feature columns\n",
    "exclude_cols = [\n",
    "    'year', 'month', 'month_num', 'month_num_parsed', \n",
    "    'actual_revenue', 'date', 'quarter_key',\n",
    "    'avg_prob_pct'  # Exclude raw probability (used only for derived features)\n",
    "]\n",
    "\n",
    "feature_cols = [\n",
    "    col for col in df_monthly.columns \n",
    "    if col not in exclude_cols \n",
    "    and df_monthly[col].dtype in ['int64', 'float64']\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal features before filtering: {len(feature_cols)}\")\n",
    "\n",
    "# Train-Test Split (temporal)\n",
    "df_model = df_monthly[df_monthly['actual_revenue'] > 0].copy()\n",
    "train_data = df_model[df_model['year'].isin([2023, 2024])].copy()\n",
    "test_data = df_model[df_model['year'] == 2025].copy()\n",
    "\n",
    "print(f\"\\nTrain (2023-2024): {len(train_data)} months\")\n",
    "print(f\"Test (2025): {len(test_data)} months\")\n",
    "\n",
    "# Prepare X and y\n",
    "X_train_raw = train_data[feature_cols]\n",
    "y_train = train_data['actual_revenue']\n",
    "X_test_raw = test_data[feature_cols]\n",
    "y_test = test_data['actual_revenue']\n",
    "\n",
    "print(f\"\\nX_train shape: {X_train_raw.shape}\")\n",
    "print(f\"X_test shape: {X_test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 7: Correlation & Redundancy Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CORRELATION & REDUNDANCY REMOVAL - PHASE 1: VARIANCE THRESHOLD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Remove low variance features\n",
    "var_threshold = VarianceThreshold(threshold=0.01)\n",
    "var_threshold.fit(X_train_raw)\n",
    "\n",
    "low_var_mask = var_threshold.get_support()\n",
    "features_after_var = [f for f, m in zip(feature_cols, low_var_mask) if m]\n",
    "features_removed_var = [f for f, m in zip(feature_cols, low_var_mask) if not m]\n",
    "\n",
    "print(f\"\\nFeatures removed due to low variance: {len(features_removed_var)}\")\n",
    "if features_removed_var:\n",
    "    for f in features_removed_var:\n",
    "        print(f\"  - {f}\")\n",
    "print(f\"\\nFeatures remaining: {len(features_after_var)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION & REDUNDANCY REMOVAL - PHASE 2: MULTICOLLINEARITY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def remove_multicollinearity(df, features, threshold=0.85):\n",
    "    \"\"\"Remove features with correlation > threshold\"\"\"\n",
    "    corr_matrix = df[features].corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    \n",
    "    # Find features to drop (keep first, drop second)\n",
    "    to_drop = []\n",
    "    for column in upper.columns:\n",
    "        if any(upper[column] > threshold):\n",
    "            # Find the feature it's correlated with\n",
    "            correlated_with = upper.index[upper[column] > threshold].tolist()\n",
    "            to_drop.append(column)\n",
    "    \n",
    "    return [f for f in features if f not in to_drop], to_drop\n",
    "\n",
    "features_after_corr, dropped_corr = remove_multicollinearity(\n",
    "    train_data, features_after_var, threshold=0.85\n",
    ")\n",
    "\n",
    "print(f\"\\nFeatures removed due to multicollinearity (>0.85): {len(dropped_corr)}\")\n",
    "print(f\"Features remaining: {len(features_after_corr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CORRELATION & REDUNDANCY REMOVAL - PHASE 3: TARGET CORRELATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate correlation with target\n",
    "target_corr = train_data[features_after_corr + ['actual_revenue']].corr()['actual_revenue'].drop('actual_revenue')\n",
    "target_corr_sorted = target_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 25 Features by Correlation with Target:\")\n",
    "for i, (feat, corr) in enumerate(target_corr_sorted.head(25).items(), 1):\n",
    "    sign = '+' if target_corr[feat] > 0 else '-'\n",
    "    print(f\"  {i:2d}. {feat}: {sign}{abs(corr):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update X with filtered features\n",
    "X_train_filtered = train_data[features_after_corr]\n",
    "X_test_filtered = test_data[features_after_corr]\n",
    "\n",
    "print(f\"\\nFiltered feature count: {len(features_after_corr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 8: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use StandardScaler (better for regularized models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test_filtered)\n",
    "\n",
    "print(f\"âœ“ Features scaled with StandardScaler\")\n",
    "print(f\"\\nX_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\ny_train range: ${y_train.min():,.0f} - ${y_train.max():,.0f}\")\n",
    "print(f\"y_test range: ${y_test.min():,.0f} - ${y_test.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 9: Feature Selection (Multiple Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE SELECTION - METHOD 1: RFE (Recursive Feature Elimination)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use Ridge for RFE (stable for small datasets)\n",
    "ridge_rfe = Ridge(alpha=10.0)\n",
    "\n",
    "# RFE with optimal number of features\n",
    "n_features_rfe = min(15, len(features_after_corr))\n",
    "rfe = RFE(estimator=ridge_rfe, n_features_to_select=n_features_rfe, step=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get selected features\n",
    "rfe_selected = [f for f, s in zip(features_after_corr, rfe.support_) if s]\n",
    "\n",
    "print(f\"\\nRFE selected {len(rfe_selected)} features:\")\n",
    "for i, feat in enumerate(rfe_selected, 1):\n",
    "    corr = target_corr[feat] if feat in target_corr else 0\n",
    "    print(f\"  {i:2d}. {feat} (corr: {corr:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SELECTION - METHOD 2: SelectFromModel (Lasso)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use Lasso for feature selection (inherent L1 sparsity)\n",
    "lasso_selector = LassoCV(cv=TimeSeriesSplit(n_splits=3), max_iter=10000, random_state=42)\n",
    "lasso_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "sfm = SelectFromModel(lasso_selector, prefit=True)\n",
    "sfm_mask = sfm.get_support()\n",
    "sfm_selected = [f for f, m in zip(features_after_corr, sfm_mask) if m]\n",
    "\n",
    "print(f\"\\nLasso SelectFromModel selected {len(sfm_selected)} features:\")\n",
    "for i, feat in enumerate(sfm_selected, 1):\n",
    "    corr = target_corr[feat] if feat in target_corr else 0\n",
    "    print(f\"  {i:2d}. {feat} (corr: {corr:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SELECTION - METHOD 3: Mutual Information\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compute mutual information scores\n",
    "mi_scores = mutual_info_regression(X_train_scaled, y_train, random_state=42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': features_after_corr,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "# Select top features by MI\n",
    "n_features_mi = min(15, len(features_after_corr))\n",
    "mi_selected = mi_df.head(n_features_mi)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nTop {n_features_mi} features by Mutual Information:\")\n",
    "for i, row in mi_df.head(n_features_mi).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['mi_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SELECTION - METHOD 4: F-Regression\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# F-regression scores\n",
    "selector_f = SelectKBest(f_regression, k=min(15, len(features_after_corr)))\n",
    "selector_f.fit(X_train_scaled, y_train)\n",
    "\n",
    "f_scores = selector_f.scores_\n",
    "f_df = pd.DataFrame({\n",
    "    'feature': features_after_corr,\n",
    "    'f_score': f_scores\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "f_selected = [f for f, m in zip(features_after_corr, selector_f.get_support()) if m]\n",
    "\n",
    "print(f\"\\nTop {len(f_selected)} features by F-Regression:\")\n",
    "for i, row in f_df.head(15).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['f_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SELECTION - ENSEMBLE: Combine All Methods\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count how many methods selected each feature\n",
    "all_selected = set(rfe_selected) | set(sfm_selected) | set(mi_selected) | set(f_selected)\n",
    "\n",
    "feature_votes = {}\n",
    "for f in all_selected:\n",
    "    votes = 0\n",
    "    if f in rfe_selected: votes += 1\n",
    "    if f in sfm_selected: votes += 1\n",
    "    if f in mi_selected: votes += 1\n",
    "    if f in f_selected: votes += 1\n",
    "    feature_votes[f] = votes\n",
    "\n",
    "# Sort by votes and correlation\n",
    "feature_ranking = sorted(\n",
    "    feature_votes.items(), \n",
    "    key=lambda x: (x[1], abs(target_corr.get(x[0], 0))), \n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"\\nFeature Ranking by Selection Method Agreement:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (feat, votes) in enumerate(feature_ranking, 1):\n",
    "    methods = []\n",
    "    if feat in rfe_selected: methods.append('RFE')\n",
    "    if feat in sfm_selected: methods.append('SFM')\n",
    "    if feat in mi_selected: methods.append('MI')\n",
    "    if feat in f_selected: methods.append('F')\n",
    "    corr = target_corr.get(feat, 0)\n",
    "    print(f\"  {i:2d}. {feat}: {votes}/4 votes, corr={corr:.4f} ({', '.join(methods)})\")\n",
    "\n",
    "# Select features with >= 2 votes\n",
    "final_features = [f for f, v in feature_ranking if v >= 2]\n",
    "\n",
    "# Limit to top 12 for small dataset\n",
    "if len(final_features) > 12:\n",
    "    final_features = final_features[:12]\n",
    "\n",
    "print(f\"\\nâœ“ Final feature set: {len(final_features)} features (>=2 votes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL FEATURE SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nFinal {len(final_features)} features selected:\")\n",
    "for i, feat in enumerate(final_features, 1):\n",
    "    corr = target_corr.get(feat, 0)\n",
    "    print(f\"  {i:2d}. {feat} (corr: {corr:.4f})\")\n",
    "\n",
    "# Update train/test sets with final features\n",
    "X_train_final = train_data[final_features]\n",
    "X_test_final = test_data[final_features]\n",
    "\n",
    "# Re-scale with final features only\n",
    "scaler_final = StandardScaler()\n",
    "X_train_scaled_final = scaler_final.fit_transform(X_train_final)\n",
    "X_test_scaled_final = scaler_final.transform(X_test_final)\n",
    "\n",
    "print(f\"\\nâœ“ Final scaled datasets ready\")\n",
    "print(f\"   X_train: {X_train_scaled_final.shape}\")\n",
    "print(f\"   X_test: {X_test_scaled_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 10: Model Training & Testing\n",
    "\n",
    "**Models:** Ridge, Lasso, ElasticNet only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL 1: RIDGE REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use RidgeCV to find optimal alpha\n",
    "alphas = np.logspace(-2, 6, 100)\n",
    "\n",
    "ridge_cv = RidgeCV(\n",
    "    alphas=alphas,\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    scoring='r2'\n",
    ")\n",
    "ridge_cv.fit(X_train_scaled_final, y_train)\n",
    "\n",
    "print(f\"\\nOptimal alpha: {ridge_cv.alpha_:.4f}\")\n",
    "\n",
    "# Train RÂ²\n",
    "y_train_pred_ridge = ridge_cv.predict(X_train_scaled_final)\n",
    "train_r2_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "train_mape_ridge = mean_absolute_percentage_error(y_train, y_train_pred_ridge) * 100\n",
    "\n",
    "# Test RÂ²\n",
    "y_test_pred_ridge = ridge_cv.predict(X_test_scaled_final)\n",
    "test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "test_mae_ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "test_mape_ridge = mean_absolute_percentage_error(y_test, y_test_pred_ridge) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Ridge Results:\")\n",
    "print(f\"   Train RÂ²: {train_r2_ridge:.4f}\")\n",
    "print(f\"   Train MAPE: {train_mape_ridge:.2f}%\")\n",
    "print(f\"   Test RÂ²: {test_r2_ridge:.4f}\")\n",
    "print(f\"   Test MAE: ${test_mae_ridge:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_mape_ridge:.2f}%\")\n",
    "print(f\"   Overfit Gap: {train_r2_ridge - test_r2_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 2: LASSO REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use LassoCV to find optimal alpha\n",
    "lasso_cv = LassoCV(\n",
    "    alphas=np.logspace(-2, 6, 100),\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "lasso_cv.fit(X_train_scaled_final, y_train)\n",
    "\n",
    "print(f\"\\nOptimal alpha: {lasso_cv.alpha_:.4f}\")\n",
    "\n",
    "# Train RÂ²\n",
    "y_train_pred_lasso = lasso_cv.predict(X_train_scaled_final)\n",
    "train_r2_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "train_mape_lasso = mean_absolute_percentage_error(y_train, y_train_pred_lasso) * 100\n",
    "\n",
    "# Test RÂ²\n",
    "y_test_pred_lasso = lasso_cv.predict(X_test_scaled_final)\n",
    "test_r2_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "test_mae_lasso = mean_absolute_error(y_test, y_test_pred_lasso)\n",
    "test_mape_lasso = mean_absolute_percentage_error(y_test, y_test_pred_lasso) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Lasso Results:\")\n",
    "print(f\"   Train RÂ²: {train_r2_lasso:.4f}\")\n",
    "print(f\"   Train MAPE: {train_mape_lasso:.2f}%\")\n",
    "print(f\"   Test RÂ²: {test_r2_lasso:.4f}\")\n",
    "print(f\"   Test MAE: ${test_mae_lasso:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_mape_lasso:.2f}%\")\n",
    "print(f\"   Overfit Gap: {train_r2_lasso - test_r2_lasso:.4f}\")\n",
    "\n",
    "# Show which features Lasso kept\n",
    "lasso_coefs = pd.DataFrame({\n",
    "    'feature': final_features,\n",
    "    'coefficient': lasso_cv.coef_\n",
    "})\n",
    "lasso_nonzero = lasso_coefs[lasso_coefs['coefficient'] != 0].sort_values('coefficient', key=abs, ascending=False)\n",
    "print(f\"\\nLasso kept {len(lasso_nonzero)} features (non-zero coefficients):\")\n",
    "for _, row in lasso_nonzero.iterrows():\n",
    "    print(f\"   {row['feature']}: {row['coefficient']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL 3: ELASTICNET REGRESSION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use ElasticNetCV to find optimal alpha and l1_ratio\n",
    "l1_ratios = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "\n",
    "enet_cv = ElasticNetCV(\n",
    "    l1_ratio=l1_ratios,\n",
    "    alphas=np.logspace(-2, 6, 50),\n",
    "    cv=TimeSeriesSplit(n_splits=3),\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "enet_cv.fit(X_train_scaled_final, y_train)\n",
    "\n",
    "print(f\"\\nOptimal alpha: {enet_cv.alpha_:.4f}\")\n",
    "print(f\"Optimal l1_ratio: {enet_cv.l1_ratio_:.2f}\")\n",
    "\n",
    "# Train RÂ²\n",
    "y_train_pred_enet = enet_cv.predict(X_train_scaled_final)\n",
    "train_r2_enet = r2_score(y_train, y_train_pred_enet)\n",
    "train_mape_enet = mean_absolute_percentage_error(y_train, y_train_pred_enet) * 100\n",
    "\n",
    "# Test RÂ²\n",
    "y_test_pred_enet = enet_cv.predict(X_test_scaled_final)\n",
    "test_r2_enet = r2_score(y_test, y_test_pred_enet)\n",
    "test_mae_enet = mean_absolute_error(y_test, y_test_pred_enet)\n",
    "test_mape_enet = mean_absolute_percentage_error(y_test, y_test_pred_enet) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š ElasticNet Results:\")\n",
    "print(f\"   Train RÂ²: {train_r2_enet:.4f}\")\n",
    "print(f\"   Train MAPE: {train_mape_enet:.2f}%\")\n",
    "print(f\"   Test RÂ²: {test_r2_enet:.4f}\")\n",
    "print(f\"   Test MAE: ${test_mae_enet:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_mape_enet:.2f}%\")\n",
    "print(f\"   Overfit Gap: {train_r2_enet - test_r2_enet:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 11: Advanced Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING - RIDGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fine-grained GridSearchCV for Ridge\n",
    "best_alpha_ridge = ridge_cv.alpha_\n",
    "alpha_range = np.linspace(max(0.01, best_alpha_ridge * 0.1), best_alpha_ridge * 10, 100)\n",
    "\n",
    "ridge_grid = GridSearchCV(\n",
    "    Ridge(),\n",
    "    param_grid={'alpha': alpha_range},\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='r2',\n",
    "    refit=True\n",
    ")\n",
    "ridge_grid.fit(X_train_scaled_final, y_train)\n",
    "\n",
    "print(f\"\\nFine-tuned Ridge alpha: {ridge_grid.best_params_['alpha']:.4f}\")\n",
    "print(f\"CV Score: {ridge_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate fine-tuned Ridge\n",
    "y_train_pred_ridge_tuned = ridge_grid.predict(X_train_scaled_final)\n",
    "y_test_pred_ridge_tuned = ridge_grid.predict(X_test_scaled_final)\n",
    "\n",
    "train_r2_ridge_tuned = r2_score(y_train, y_train_pred_ridge_tuned)\n",
    "test_r2_ridge_tuned = r2_score(y_test, y_test_pred_ridge_tuned)\n",
    "test_mae_ridge_tuned = mean_absolute_error(y_test, y_test_pred_ridge_tuned)\n",
    "test_mape_ridge_tuned = mean_absolute_percentage_error(y_test, y_test_pred_ridge_tuned) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Fine-Tuned Ridge Results:\")\n",
    "print(f\"   Train RÂ²: {train_r2_ridge_tuned:.4f}\")\n",
    "print(f\"   Test RÂ²: {test_r2_ridge_tuned:.4f}\")\n",
    "print(f\"   Test MAE: ${test_mae_ridge_tuned:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_mape_ridge_tuned:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER TUNING - ELASTICNET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fine-grained GridSearchCV for ElasticNet\n",
    "best_alpha_enet = enet_cv.alpha_\n",
    "best_l1_enet = enet_cv.l1_ratio_\n",
    "\n",
    "enet_grid = GridSearchCV(\n",
    "    ElasticNet(max_iter=10000, random_state=42),\n",
    "    param_grid={\n",
    "        'alpha': np.linspace(max(0.01, best_alpha_enet * 0.5), best_alpha_enet * 2, 30),\n",
    "        'l1_ratio': np.linspace(max(0.1, best_l1_enet - 0.2), min(0.99, best_l1_enet + 0.2), 15)\n",
    "    },\n",
    "    cv=TimeSeriesSplit(n_splits=5),\n",
    "    scoring='r2',\n",
    "    refit=True\n",
    ")\n",
    "enet_grid.fit(X_train_scaled_final, y_train)\n",
    "\n",
    "print(f\"\\nFine-tuned ElasticNet alpha: {enet_grid.best_params_['alpha']:.4f}\")\n",
    "print(f\"Fine-tuned ElasticNet l1_ratio: {enet_grid.best_params_['l1_ratio']:.4f}\")\n",
    "print(f\"CV Score: {enet_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate fine-tuned ElasticNet\n",
    "y_train_pred_enet_tuned = enet_grid.predict(X_train_scaled_final)\n",
    "y_test_pred_enet_tuned = enet_grid.predict(X_test_scaled_final)\n",
    "\n",
    "train_r2_enet_tuned = r2_score(y_train, y_train_pred_enet_tuned)\n",
    "test_r2_enet_tuned = r2_score(y_test, y_test_pred_enet_tuned)\n",
    "test_mae_enet_tuned = mean_absolute_error(y_test, y_test_pred_enet_tuned)\n",
    "test_mape_enet_tuned = mean_absolute_percentage_error(y_test, y_test_pred_enet_tuned) * 100\n",
    "\n",
    "print(f\"\\nðŸ“Š Fine-Tuned ElasticNet Results:\")\n",
    "print(f\"   Train RÂ²: {train_r2_enet_tuned:.4f}\")\n",
    "print(f\"   Test RÂ²: {test_r2_enet_tuned:.4f}\")\n",
    "print(f\"   Test MAE: ${test_mae_enet_tuned:,.0f}\")\n",
    "print(f\"   Test MAPE: {test_mape_enet_tuned:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 12: Model Comparison & Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Compile results\n",
    "results = [\n",
    "    ('Ridge (CV)', train_r2_ridge, test_r2_ridge, test_mape_ridge, test_mae_ridge),\n",
    "    ('Ridge (Tuned)', train_r2_ridge_tuned, test_r2_ridge_tuned, test_mape_ridge_tuned, test_mae_ridge_tuned),\n",
    "    ('Lasso (CV)', train_r2_lasso, test_r2_lasso, test_mape_lasso, test_mae_lasso),\n",
    "    ('ElasticNet (CV)', train_r2_enet, test_r2_enet, test_mape_enet, test_mae_enet),\n",
    "    ('ElasticNet (Tuned)', train_r2_enet_tuned, test_r2_enet_tuned, test_mape_enet_tuned, test_mae_enet_tuned)\n",
    "]\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Model', 'Train RÂ²', 'Test RÂ²', 'Test MAPE (%)', 'Test MAE ($)'])\n",
    "results_df['Overfit Gap'] = results_df['Train RÂ²'] - results_df['Test RÂ²']\n",
    "results_df = results_df.sort_values('Test RÂ²', ascending=False)\n",
    "\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_test_r2 = results_df.iloc[0]['Test RÂ²']\n",
    "best_mape = results_df.iloc[0]['Test MAPE (%)']\n",
    "best_mae = results_df.iloc[0]['Test MAE ($)']\n",
    "\n",
    "print(f\"\\nðŸ† BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test RÂ²: {best_test_r2:.4f}\")\n",
    "print(f\"   Test MAPE: {best_mape:.2f}%\")\n",
    "print(f\"   Test MAE: ${best_mae:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. RÂ² Comparison\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, results_df['Train RÂ²'], width, label='Train RÂ²', color='steelblue', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, results_df['Test RÂ²'], width, label='Test RÂ²', color='darkorange', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Model')\n",
    "ax1.set_ylabel('RÂ² Score')\n",
    "ax1.set_title('RÂ² Comparison: Train vs Test')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.set_ylim(min(0, results_df['Test RÂ²'].min() - 0.1), 1.0)\n",
    "\n",
    "# 2. MAPE Comparison\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(results_df['Model'], results_df['Test MAPE (%)'], color='seagreen', alpha=0.8)\n",
    "ax2.set_xlabel('Model')\n",
    "ax2.set_ylabel('Test MAPE (%)')\n",
    "ax2.set_title('Test MAPE Comparison (Lower is Better)')\n",
    "ax2.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 13: Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FEATURE IMPORTANCE (Best Model Coefficients)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get coefficients from best model\n",
    "if 'Ridge' in best_model_name:\n",
    "    if 'Tuned' in best_model_name:\n",
    "        best_model = ridge_grid.best_estimator_\n",
    "    else:\n",
    "        best_model = ridge_cv\n",
    "elif 'Lasso' in best_model_name:\n",
    "    best_model = lasso_cv\n",
    "else:\n",
    "    if 'Tuned' in best_model_name:\n",
    "        best_model = enet_grid.best_estimator_\n",
    "    else:\n",
    "        best_model = enet_cv\n",
    "\n",
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': final_features,\n",
    "    'coefficient': best_model.coef_\n",
    "})\n",
    "importance_df['abs_coef'] = importance_df['coefficient'].abs()\n",
    "importance_df = importance_df.sort_values('abs_coef', ascending=False)\n",
    "\n",
    "print(f\"\\n{best_model_name} Feature Importance:\")\n",
    "print(\"-\" * 50)\n",
    "for i, row in importance_df.iterrows():\n",
    "    sign = '+' if row['coefficient'] > 0 else '-'\n",
    "    print(f\"  {row['feature']}: {sign}{abs(row['coefficient']):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = ['green' if c > 0 else 'red' for c in importance_df['coefficient']]\n",
    "ax.barh(importance_df['feature'], importance_df['coefficient'], color=colors, alpha=0.7)\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_title(f'{best_model_name} - Feature Coefficients')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 14: Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PREDICTION ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get predictions from best model\n",
    "if 'Ridge' in best_model_name:\n",
    "    if 'Tuned' in best_model_name:\n",
    "        best_predictions = y_test_pred_ridge_tuned\n",
    "    else:\n",
    "        best_predictions = y_test_pred_ridge\n",
    "elif 'Lasso' in best_model_name:\n",
    "    best_predictions = y_test_pred_lasso\n",
    "else:\n",
    "    if 'Tuned' in best_model_name:\n",
    "        best_predictions = y_test_pred_enet_tuned\n",
    "    else:\n",
    "        best_predictions = y_test_pred_enet\n",
    "\n",
    "# Prediction comparison table\n",
    "pred_df = pd.DataFrame({\n",
    "    'Month': test_data['month'].values,\n",
    "    'Year': test_data['year'].values,\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': best_predictions,\n",
    "    'Error': y_test.values - best_predictions,\n",
    "    'Error %': ((y_test.values - best_predictions) / y_test.values) * 100\n",
    "})\n",
    "\n",
    "print(\"\\n2025 Predictions vs Actual:\")\n",
    "print(\"-\" * 80)\n",
    "for _, row in pred_df.iterrows():\n",
    "    print(f\"  {row['Month']} {int(row['Year'])}: \" +\n",
    "          f\"Actual=${row['Actual']:,.0f}, \" +\n",
    "          f\"Pred=${row['Predicted']:,.0f}, \" +\n",
    "          f\"Error={row['Error %']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Actual vs Predicted\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Time series comparison\n",
    "ax1 = axes[0]\n",
    "months = range(1, len(y_test) + 1)\n",
    "ax1.plot(months, y_test.values, 'bo-', label='Actual', linewidth=2, markersize=8)\n",
    "ax1.plot(months, best_predictions, 'r^--', label='Predicted', linewidth=2, markersize=8)\n",
    "ax1.fill_between(months, y_test.values, best_predictions, alpha=0.2, color='gray')\n",
    "ax1.set_xlabel('Month (2025)')\n",
    "ax1.set_ylabel('Revenue ($)')\n",
    "ax1.set_title('2025 Revenue: Actual vs Predicted')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scatter plot\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(y_test, best_predictions, c='steelblue', s=100, alpha=0.7, edgecolors='black')\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(y_test.min(), best_predictions.min())\n",
    "max_val = max(y_test.max(), best_predictions.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "ax2.set_xlabel('Actual Revenue ($)')\n",
    "ax2.set_ylabel('Predicted Revenue ($)')\n",
    "ax2.set_title(f'Actual vs Predicted (RÂ² = {best_test_r2:.4f})')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 15: Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Analysis\n",
    "residuals = y_test.values - best_predictions\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Residual distribution\n",
    "ax1 = axes[0]\n",
    "ax1.hist(residuals, bins=10, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Residual ($)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Residual Distribution')\n",
    "\n",
    "# 2. Residuals vs Predicted\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(best_predictions, residuals, c='steelblue', s=80, alpha=0.7, edgecolors='black')\n",
    "ax2.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Predicted Revenue ($)')\n",
    "ax2.set_ylabel('Residual ($)')\n",
    "ax2.set_title('Residuals vs Predicted')\n",
    "\n",
    "# 3. Q-Q Plot\n",
    "ax3 = axes[2]\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax3)\n",
    "ax3.set_title('Q-Q Plot (Normality Check)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Residual statistics\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean: ${np.mean(residuals):,.0f}\")\n",
    "print(f\"  Std: ${np.std(residuals):,.0f}\")\n",
    "print(f\"  Min: ${np.min(residuals):,.0f}\")\n",
    "print(f\"  Max: ${np.max(residuals):,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## STEP 16: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š PIPELINE RESULTS:\n",
    "\n",
    "1. DATA:\n",
    "   - Total samples: {len(df_monthly)}\n",
    "   - Train (2023-2024): {len(train_data)} months\n",
    "   - Test (2025): {len(test_data)} months\n",
    "\n",
    "2. FEATURE ENGINEERING:\n",
    "   - Total features created: {len(feature_cols)}\n",
    "   - Features after variance filter: {len(features_after_var)}\n",
    "   - Features after multicollinearity removal: {len(features_after_corr)}\n",
    "   - Final features selected: {len(final_features)}\n",
    "\n",
    "3. KEY DOMAIN FEATURES CREATED:\n",
    "   âœ“ weighted_revenue (expected value = forecast Ã— prob)\n",
    "   âœ“ revenue_momentum_1m (lag1 - lag2, growth indicator)\n",
    "   âœ“ loading_factor (month-in-quarter loading)\n",
    "   âœ“ gap_ratio (weighted/unweighted, pipeline maturity)\n",
    "   âœ“ coverage_pipeline (pipeline sufficiency)\n",
    "   âœ“ maturity_rate (conversion efficiency)\n",
    "   âœ“ structural_feature (quarter loading structure)\n",
    "   âœ“ pipeline_stability (1/variance, consistency score)\n",
    "\n",
    "4. FEATURE SELECTION METHODS USED:\n",
    "   âœ“ RFE (Recursive Feature Elimination)\n",
    "   âœ“ SelectFromModel (Lasso-based)\n",
    "   âœ“ Mutual Information\n",
    "   âœ“ F-Regression\n",
    "   âœ“ Ensemble voting (features with >=2 votes selected)\n",
    "\n",
    "5. BEST MODEL: {best_model_name}\n",
    "   - Test RÂ²: {best_test_r2:.4f}\n",
    "   - Test MAPE: {best_mape:.2f}%\n",
    "   - Test MAE: ${best_mae:,.0f}\n",
    "\n",
    "6. FINAL FEATURES ({len(final_features)}):\"\"\")\n",
    "\n",
    "for i, feat in enumerate(final_features, 1):\n",
    "    print(f\"   {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "7. MODEL COMPARISON:\n",
    "{results_df.to_string(index=False)}\n",
    "\n",
    "8. PIPELINE FOLLOWED:\n",
    "   âœ“ Feature Engineering (19 phases)\n",
    "   âœ“ Leakage Checks (correlation + linear combination + business logic)\n",
    "   âœ“ Missing Value Handling (fillna + inf replacement)\n",
    "   âœ“ Proper Data Splitting (temporal train/test)\n",
    "   âœ“ Encoding & Scaling (StandardScaler)\n",
    "   âœ“ Correlation & Redundancy Removal (variance + multicollinearity)\n",
    "   âœ“ Feature Selection (RFE + SFM + MI + F-regression ensemble)\n",
    "   âœ“ Model Test (Ridge, Lasso, ElasticNet)\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
